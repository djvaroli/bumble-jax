{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why the Scaling Factor in Scalted Dot Product Attention?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Attention}(Q,K,V)=\\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attention mechanism in transformers was my introducton into the idea of \"attention\" in neural networks and the first time I saw it, there was one part that appeared trivial to me. \n",
    "\n",
    "I knew what the Softmax function was and I knew what it produces as the output. Though that wasn't it. Keys, Queries and Values were completely foreign to me, so looking at it firs time definitely did not seem trivial. In fact, it felt like the hardest thing about transformers. \n",
    "\n",
    "So what was it that I found trivial in this newly discovered attention mechanism? \n",
    "\n",
    "The scaling factor! It's just division right? Make the numbers a bit smaller because that worked experimentally, so no need to focus on that. \n",
    "\n",
    "At the time, considering I knew nothing about attention, that was the right call. It was much more important to understand the idea of attention, rather than the little details. However, now, after many years of wokring with transformers, reading and re-reading many tutorials, papers and posts about it, I've decided to take another look. Why divide by anything? Why the square root? Why $d_k$? \n",
    "\n",
    "This is the question I want to answer with a few examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Is This Important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would say that it really depends. If attention is a brand new concept for you, then there are plenty of incredible resources out there to help you walk through attention and its application in transformers. Even if you have a decent understaning of it, answering this specific question may not be necessary or even that important or impactful. \n",
    "\n",
    "<b>So then why do I want to answer it?</b>\n",
    "\n",
    "Machine learning, deep learning and probably anything that involves implemented algorithms comes with tricks, sleights of hand or little gems of someone's intuition that sometimes make all the difference. Applying normalization to gradients, how you initialize weights, applying residual connections, changing the order of some layers in a neural network sometimes appear so simple and yet they can end up having profound effects. I want to understanding the rationale behind them so that I can develop my own intution and read these algorithms more as a story than equations and numbers. I beleive that at the right moment with the right setting these gems can help myself and others make all the difference too! Which is why I want to share my workings with others. \n",
    "\n",
    "It's such an amazing feeling to understand something to the level where you begin to appreciate its signficance and it's even more incredible when you see something similar in another place and can transfer that understanding to a different problem! I want to help others have more of those moments, which is why I am sharing these workings, I'm sure someone will find them insightful too! \n",
    "\n",
    "Let's look at some code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "import jax\n",
    "from jax import random\n",
    "from jax import numpy as jnp\n",
    "from rich.syntax import Syntax\n",
    "from rich import print\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from attention.dotprod import scaled_dot_product_attn, _scaled_dot_product_attention_with_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the main RNG to make the notebook reproducible\n",
    "main_rng = random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first examine how I implemented the scaled dot product attention function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 1 </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">@jax</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">vmap</span><span style=\"background-color: #272822\">                                                                                                     </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 2 </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">def</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">_scaled_dot_product_attention_with_logits</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(</span><span style=\"background-color: #272822\">                                                                </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 3 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    q: Array,</span><span style=\"background-color: #272822\">                                                                                                 </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 4 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    k: Array,</span><span style=\"background-color: #272822\">                                                                                                 </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 5 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    v: Array,</span><span style=\"background-color: #272822\">                                                                                                 </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 6 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    mask: Optional[Array] </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">None</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                             </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 7 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">-&gt;</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> Tuple[Array, Array, Array]:</span><span style=\"background-color: #272822\">                                                                              </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 8 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"\"\"Performs scaled dot product attention for a single attention head.</span><span style=\"background-color: #272822\">                                     </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 9 </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">10 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">    Note:</span><span style=\"background-color: #272822\">                                                                                                     </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">11 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">        * function is vectorized over the batch dimension using jax.vmap.</span><span style=\"background-color: #272822\">                                     </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">12 </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">13 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">    Args:</span><span style=\"background-color: #272822\">                                                                                                     </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">14 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">        q (Array): query matrix with shape (seq_len, Dk).</span><span style=\"background-color: #272822\">                                                     </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">15 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">        k (Array): keys matrix with shape (seq_len, Dk).</span><span style=\"background-color: #272822\">                                                      </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">16 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">        v (Array): values matrix with shape (seq_len, Dv).</span><span style=\"background-color: #272822\">                                                    </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">17 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">        mask (Optional[Array], optional): padding mask with shape (seq_len, seq_len). Defaults to None.</span><span style=\"background-color: #272822\">       </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">18 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">            If specified must be a binary matrix with 1s indicating valid positions and 0s indicating masked p</span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">19 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">            Expected shape is (seq_len, seq_len) where seq_len is the length of the sequence.</span><span style=\"background-color: #272822\">                 </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">20 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">        </span><span style=\"background-color: #272822\">                                                                                                      </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">21 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">    Returns:</span><span style=\"background-color: #272822\">                                                                                                  </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">22 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">        Tuple[Array, Array]: </span><span style=\"background-color: #272822\">                                                                                 </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">23 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">            Array: scaled dot product attention output with shape (seq_len, Dv).</span><span style=\"background-color: #272822\">                              </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">24 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">            Array: attention weights with shape (seq_len, seq_len).</span><span style=\"background-color: #272822\">                                           </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">25 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">            Array: attention logits with shape (seq_len, seq_len).</span><span style=\"background-color: #272822\">                                            </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">26 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">    \"\"\"</span><span style=\"background-color: #272822\">                                                                                                       </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">27 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    seq_len, vector_dim </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> q</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">shape</span><span style=\"background-color: #272822\">                                                                             </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">28 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">if</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> mask </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">is</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">None</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">:</span><span style=\"background-color: #272822\">                                                                                          </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">29 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        mask </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> jnp</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">ones((seq_len, seq_len))</span><span style=\"background-color: #272822\">                                                                   </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">30 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"background-color: #272822\">                                                                                                          </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">31 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># will ensure that variance of dot product remains sigma^4 ~= 1 since we init with sigma = 1</span><span style=\"background-color: #272822\">              </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">32 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># see dotprod-step-by-step.ipynb for more details</span><span style=\"background-color: #272822\">                                                         </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">33 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    variance_scale_factor </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">1</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">/</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> jnp</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">sqrt(vector_dim)</span><span style=\"background-color: #272822\">                                                          </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">34 </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">35 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># compute QK^T, transpose K to get (Dk, seq_len)</span><span style=\"background-color: #272822\">                                                          </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">36 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># output shape (seq_len, seq_len)</span><span style=\"background-color: #272822\">                                                                         </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">37 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    attention_logits </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> jnp</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">matmul(q, jnp</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">swapaxes(k, </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">1</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)) </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">*</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> variance_scale_factor</span><span style=\"background-color: #272822\">                           </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">38 </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">39 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># apply mask if provided</span><span style=\"background-color: #272822\">                                                                                  </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">40 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># positions at 1 remain unchanged, positions at 0 are set to -inf (-1e10)</span><span style=\"background-color: #272822\">                                 </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">41 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># 1 - mask = 1 for masked positions, 0 for valid positions</span><span style=\"background-color: #272822\">                                                </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">42 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    attention_logits </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> attention_logits </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">-</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">1e10</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">*</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> (</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">1</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">-</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> mask)</span><span style=\"background-color: #272822\">                                                   </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">43 </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">44 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># apply softmax element-wise along the rows</span><span style=\"background-color: #272822\">                                                               </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">45 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    attention_weights </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> jax</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nn</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">softmax(attention_logits, axis</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=-</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">1</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                             </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">46 </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">47 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># weighted average of value vectors (weighted retrieval)</span><span style=\"background-color: #272822\">                                                  </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">48 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    result </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> jnp</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">matmul(attention_weights, v)</span><span style=\"background-color: #272822\">                                                                 </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">49 </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">50 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">return</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> result, attention_weights, attention_logits</span><span style=\"background-color: #272822\">                                                        </span>\n",
       "<span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">51 </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 1 \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34m@jax\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mvmap\u001b[0m\u001b[48;2;39;40;34m                                                                                                     \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 2 \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mdef\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34m_scaled_dot_product_attention_with_logits\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[48;2;39;40;34m                                                                \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 3 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mq\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mArray\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 4 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mk\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mArray\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 5 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mv\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mArray\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 6 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmask\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mOptional\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mArray\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mNone\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                             \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 7 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m-\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m>\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mTuple\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mArray\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mArray\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mArray\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                              \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 8 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\"\"Performs scaled dot product attention for a single attention head.\u001b[0m\u001b[48;2;39;40;34m                                     \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 9 \u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m10 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m    Note:\u001b[0m\u001b[48;2;39;40;34m                                                                                                     \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m11 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m        * function is vectorized over the batch dimension using jax.vmap.\u001b[0m\u001b[48;2;39;40;34m                                     \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m12 \u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m13 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m    Args:\u001b[0m\u001b[48;2;39;40;34m                                                                                                     \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m14 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m        q (Array): query matrix with shape (seq_len, Dk).\u001b[0m\u001b[48;2;39;40;34m                                                     \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m15 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m        k (Array): keys matrix with shape (seq_len, Dk).\u001b[0m\u001b[48;2;39;40;34m                                                      \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m16 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m        v (Array): values matrix with shape (seq_len, Dv).\u001b[0m\u001b[48;2;39;40;34m                                                    \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m17 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m        mask (Optional[Array], optional): padding mask with shape (seq_len, seq_len). Defaults to None.\u001b[0m\u001b[48;2;39;40;34m       \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m18 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m            If specified must be a binary matrix with 1s indicating valid positions and 0s indicating masked p\u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m19 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m            Expected shape is (seq_len, seq_len) where seq_len is the length of the sequence.\u001b[0m\u001b[48;2;39;40;34m                 \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m20 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m        \u001b[0m\u001b[48;2;39;40;34m                                                                                                      \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m21 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m    Returns:\u001b[0m\u001b[48;2;39;40;34m                                                                                                  \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m22 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m        Tuple[Array, Array]: \u001b[0m\u001b[48;2;39;40;34m                                                                                 \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m23 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m            Array: scaled dot product attention output with shape (seq_len, Dv).\u001b[0m\u001b[48;2;39;40;34m                              \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m24 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m            Array: attention weights with shape (seq_len, seq_len).\u001b[0m\u001b[48;2;39;40;34m                                           \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m25 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m            Array: attention logits with shape (seq_len, seq_len).\u001b[0m\u001b[48;2;39;40;34m                                            \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m26 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m    \"\"\"\u001b[0m\u001b[48;2;39;40;34m                                                                                                       \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m27 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mseq_len\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mvector_dim\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mq\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mshape\u001b[0m\u001b[48;2;39;40;34m                                                                             \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m28 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mif\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmask\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mis\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mNone\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                                          \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m29 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmask\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mjnp\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mones\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mseq_len\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mseq_len\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                   \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m30 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[48;2;39;40;34m                                                                                                          \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m31 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# will ensure that variance of dot product remains sigma^4 ~= 1 since we init with sigma = 1\u001b[0m\u001b[48;2;39;40;34m              \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m32 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# see dotprod-step-by-step.ipynb for more details\u001b[0m\u001b[48;2;39;40;34m                                                         \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m33 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mvariance_scale_factor\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m1\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m/\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mjnp\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msqrt\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mvector_dim\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                          \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m34 \u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m35 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# compute QK^T, transpose K to get (Dk, seq_len)\u001b[0m\u001b[48;2;39;40;34m                                                          \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m36 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# output shape (seq_len, seq_len)\u001b[0m\u001b[48;2;39;40;34m                                                                         \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m37 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mattention_logits\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mjnp\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmatmul\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mq\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mjnp\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mswapaxes\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mk\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m1\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m*\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mvariance_scale_factor\u001b[0m\u001b[48;2;39;40;34m                           \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m38 \u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m39 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# apply mask if provided\u001b[0m\u001b[48;2;39;40;34m                                                                                  \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m40 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# positions at 1 remain unchanged, positions at 0 are set to -inf (-1e10)\u001b[0m\u001b[48;2;39;40;34m                                 \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m41 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# 1 - mask = 1 for masked positions, 0 for valid positions\u001b[0m\u001b[48;2;39;40;34m                                                \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m42 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mattention_logits\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mattention_logits\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m-\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m1e10\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m*\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m1\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m-\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmask\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                   \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m43 \u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m44 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# apply softmax element-wise along the rows\u001b[0m\u001b[48;2;39;40;34m                                                               \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m45 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mattention_weights\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mjax\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnn\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msoftmax\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mattention_logits\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34maxis\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m-\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m1\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                             \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m46 \u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m47 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# weighted average of value vectors (weighted retrieval)\u001b[0m\u001b[48;2;39;40;34m                                                  \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m48 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresult\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mjnp\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmatmul\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mattention_weights\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mv\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                 \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m49 \u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m50 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mreturn\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresult\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mattention_weights\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mattention_logits\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m\n",
       "\u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m51 \u001b[0m\u001b[48;2;39;40;34m                                                                                                              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lines = inspect.getsource(_scaled_dot_product_attention_with_logits)\n",
    "syntax = Syntax(lines, lexer=\"python\", line_numbers=True)\n",
    "print(syntax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance Scaling Factor\n",
    "\n",
    "If you look at line 33 (at the time of writing) you will see that we define a `variance_scale_factor` definde as  \n",
    "\n",
    "$$\\text{variance\\textunderscore scale\\textunderscore factor} = \\frac{1}{\\sqrt{d_k}}$$\n",
    "\n",
    "We then divide the product of the Q and K matrices by that factor. Why?\n",
    "\n",
    "Most sources the internet, including the original [\"Attention Is All You Neeed Paper\"](https://arxiv.org/abs/1706.03762) explain that this scaling is needed to prevent the softmax from getting saturated (i.e. one value being very close to 1 and others very close 0) which would result in very small gradients (see [here](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative) for derivation of softmax derivative). \n",
    "\n",
    "Some resources (i.e. [this notebook](https://colab.research.google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/JAX/tutorial6/Transformers_and_MHAttention.ipynb#scrollTo=T1yF9TRkpXWq)) provide deeper insight explaining that the variance of the dot product vector increases with $d_k$. Higher variance means that one value can become very large squishing others after the softmax is applied. However, why is that actually the case? I want to walk through this step by step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before We Begin\n",
    "\n",
    "A critical piece of information is to see what happens after we multiply the `queries` and `keys` matrices and scale them. Well, we apply the `Softmax` function. \n",
    "\n",
    "The softmax function is designed as follows \n",
    "\n",
    "$$\\sigma(\\mathbf{z})_i = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}$$\n",
    "\n",
    "It takes an array of numbers and scales them such that they sum up to 1. Let's look at a few examples in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_matrix(name, matrix):\n",
    "    print(f\"[bold]{name}\\n{matrix}[/bold]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Array</span>\n",
       "<span style=\"font-weight: bold\">[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">.  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.4</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.6</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\"> [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.8</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">.  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.2</span><span style=\"font-weight: bold\">]]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mArray\u001b[0m\n",
       "\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m.  \u001b[0m\u001b[1;36m2.4\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m3.6\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m4.8\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m6\u001b[0m\u001b[1m.  \u001b[0m\u001b[1;36m5.2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Softmax</span><span style=\"font-weight: bold\">(Array)</span>\n",
       "<span style=\"font-weight: bold\">[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.296654</span><span style=\"font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1628072</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5405388</span><span style=\"font-weight: bold\"> ]</span>\n",
       "<span style=\"font-weight: bold\"> [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.17205958</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.57125777</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2566826</span><span style=\"font-weight: bold\"> ]]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSoftmax\u001b[0m\u001b[1m(\u001b[0m\u001b[1mArray\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.296654\u001b[0m\u001b[1m   \u001b[0m\u001b[1;36m0.1628072\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m0.5405388\u001b[0m\u001b[1m \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.17205958\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.57125777\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.2566826\u001b[0m\u001b[1m \u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arr = jnp.asarray([[3, 2.4, 3.6], [4.8, 6, 5.2]])\n",
    "print_matrix(\"Array\", arr)\n",
    "\n",
    "# apply softmax\n",
    "soft_arr = jax.nn.softmax(arr)\n",
    "print_matrix(\"Softmax(Array)\", soft_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the largest values in our original array are still the largest values in our transformed array, but all numbers have been scaled such that they add up to 1 (along the rows). This is grat because we can use these numbers as probabilities or as a weights for example. \n",
    "\n",
    "However, what happens, when one number because quite a bit larger than the others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Array</span>\n",
       "<span style=\"font-weight: bold\">[[ </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">.   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.4</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">. ]</span>\n",
       "<span style=\"font-weight: bold\"> [ </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.8</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">.   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.2</span><span style=\"font-weight: bold\">]]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mArray\u001b[0m\n",
       "\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m.   \u001b[0m\u001b[1;36m2.4\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m10\u001b[0m\u001b[1m. \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1m[\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m4.8\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m10\u001b[0m\u001b[1m.   \u001b[0m\u001b[1;36m5.2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Softmax</span><span style=\"font-weight: bold\">(Array)</span>\n",
       "<span style=\"font-weight: bold\">[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.1059587e-04</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.9974566e-04</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.9858958e-01</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\"> [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.4417616e-03</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.8644012e-01</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.1181517e-03</span><span style=\"font-weight: bold\">]]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSoftmax\u001b[0m\u001b[1m(\u001b[0m\u001b[1mArray\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m9.1059587e-04\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m4.9974566e-04\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m9.9858958e-01\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m5.4417616e-03\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m9.8644012e-01\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m8.1181517e-03\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arr = jnp.asarray([[3, 2.4, 10], [4.8, 10, 5.2]])\n",
    "print_matrix(\"Array\", arr)\n",
    "\n",
    "# apply softmax\n",
    "soft_arr = jax.nn.softmax(arr)\n",
    "print_matrix(\"Softmax(Array)\", soft_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The softmax becomes saturated. What does that mean? That one value becomes very close to 1 while the others are close to 0. The effects get worse as the range of the numbers in the array gets larger. The largest value in the arrays squashes out the other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Array</span>\n",
       "<span style=\"font-weight: bold\">[[ </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.4</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">. ]</span>\n",
       "<span style=\"font-weight: bold\"> [ </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">.   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.2</span><span style=\"font-weight: bold\">]]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mArray\u001b[0m\n",
       "\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m2.4\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m10\u001b[0m\u001b[1m. \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1m[\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m10\u001b[0m\u001b[1m.   \u001b[0m\u001b[1;36m5.2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Softmax</span><span style=\"font-weight: bold\">(Array)</span>\n",
       "<span style=\"font-weight: bold\">[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.01470895e-05</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.00176044e-04</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.99449670e-01</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\"> [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.00204634e-04</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.91738021e-01</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.16175155e-03</span><span style=\"font-weight: bold\">]]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSoftmax\u001b[0m\u001b[1m(\u001b[0m\u001b[1mArray\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m5.01470895e-05\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m5.00176044e-04\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m9.99449670e-01\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1.00204634e-04\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m9.91738021e-01\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m8.16175155e-03\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arr = jnp.asarray([[0.1, 2.4, 10], [0.8, 10, 5.2]])\n",
    "print_matrix(\"Array\", arr)\n",
    "\n",
    "# apply softmax\n",
    "soft_arr = jax.nn.softmax(arr)\n",
    "print_matrix(\"Softmax(Array)\", soft_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So Why Is That A Problem?\n",
    "\n",
    "This can become a serious issue in a neural network during back-propagation. Consider the derivative of the softmax (see [here](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative) for derivation)\n",
    "\n",
    "$$S_j = \\frac{e^{a_j}}{\\sum_{k=1}^{N} e^{a_k}} \\quad \\forall j \\in 1..N$$\n",
    "\n",
    "$$D_{j} S_{i} = \\begin{cases} \n",
    "S_{i}(1 - S_{j}) & \\text{if } i = j \\\\\n",
    "-S_{j} S_{i} & \\text{if } i \\neq j \n",
    "\\end{cases}$$\n",
    "\n",
    "When the softmax saturates, i.e. one value approaches 1 and others approach 0, this leads to the derivative being tiny (as per the equation above). This makes it much harder for the nueral network to learn as weight updates happen slower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to avoid that when we multiply our `Queries` and `Keys` matrices. We want to make sure that they do not produce values, such that when they are passed through the softmax would result in a wild range of numbers causing the output of the softmax to saturate. \n",
    "\n",
    "Spoiler! That's why we apply the scaling, which is what other sources explain. However, let's see the details of why we need it. Why is it that the product of the `Quries` and `Keys` matrices results in numbers that would saturate the softmax?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Time!\n",
    "\n",
    "I am going to initialize two matrices where each entry is sampled from a standard normal distribution, i.e. $X \\sim \\mathcal{N}(0, 1)$\n",
    "\n",
    "<b>Why two matrices? Aren't there three in the attention equation?</b>\n",
    "\n",
    "Yes, there are! However, here we are going to forget about the last step of multiplying by the values matrix, we're concerned with the scaling factor!\n",
    "\n",
    "<b>Ok, and why sample from the standard normal distribution?</b>\n",
    "\n",
    "We want the mean of our values to be close to zero to ensure that we keep activiations of the neural network from exploding (but not zero because zero will result in zero gradients). For the variance, we want to keep the range of our values small specifically to avoid saturation when applying the softmax function. Too small of a variance could result in similar updates being made to many weights which could cause neurons to change symmetrically and lead to poorer model performance. On the other hand too large of a variance and we could end up with softmax saturation and vanishing gradients. A variance of `1` appears to be a reasonable choice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "key1, key2 = random.split(main_rng, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "seq_len = 100\n",
    "d_q = d_k = 1000\n",
    "\n",
    "q = random.normal(key1, (batch_size, seq_len, d_q))\n",
    "k = random.normal(key2, (batch_size, seq_len, d_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">q mean: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0005608737701550126</span><span style=\"font-weight: bold\">, std: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9991742372512817</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mq mean: \u001b[0m\u001b[1;36m-0.0005608737701550126\u001b[0m\u001b[1m, std: \u001b[0m\u001b[1;36m0.9991742372512817\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">k mean: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0010934597812592983</span><span style=\"font-weight: bold\">, std: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0024572610855103</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mk mean: \u001b[0m\u001b[1;36m0.0010934597812592983\u001b[0m\u001b[1m, std: \u001b[0m\u001b[1;36m1.0024572610855103\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print mean and std of q and k\n",
    "print(f\"[bold]q mean: {jnp.mean(q)}, std: {jnp.std(q)}[/bold]\")\n",
    "print(f\"[bold]k mean: {jnp.mean(k)}, std: {jnp.std(k)}[/bold]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at their means and standard deviations, we see that they're close to the 0 and 1 we initialized them with. Great, no surprises there. \n",
    "Let's multiply the two (like in attention) and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">attn_logits</span>\n",
       "<span style=\"font-weight: bold\">[[[  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.58258057</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-6.9096413</span><span style=\"font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32.7293</span><span style=\"font-weight: bold\">     </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.75351</span><span style=\"font-weight: bold\">    </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-12.444878</span>\n",
       "<span style=\"font-weight: bold\">    </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29.457623</span><span style=\"font-weight: bold\">  ]</span>\n",
       "<span style=\"font-weight: bold\">  [  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.389431</span><span style=\"font-weight: bold\">    </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24.134903</span><span style=\"font-weight: bold\">     </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.4726806</span><span style=\"font-weight: bold\">  </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">53.15055</span><span style=\"font-weight: bold\">     </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23.586643</span>\n",
       "<span style=\"font-weight: bold\">    </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27.149685</span><span style=\"font-weight: bold\">  ]</span>\n",
       "<span style=\"font-weight: bold\">  [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-29.103306</span><span style=\"font-weight: bold\">    </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.96471</span><span style=\"font-weight: bold\">     </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">69.86938</span><span style=\"font-weight: bold\">    </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48.208244</span><span style=\"font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-49.304134</span>\n",
       "<span style=\"font-weight: bold\">    </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38.2608</span><span style=\"font-weight: bold\">    ]</span>\n",
       "<span style=\"font-weight: bold\">  </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span>\n",
       "<span style=\"font-weight: bold\">  [ </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.397432</span><span style=\"font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-38.604023</span><span style=\"font-weight: bold\">    </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25.956514</span><span style=\"font-weight: bold\">   </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-30.788982</span><span style=\"font-weight: bold\">    </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20.908705</span>\n",
       "<span style=\"font-weight: bold\">    </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77.33066</span><span style=\"font-weight: bold\">   ]</span>\n",
       "<span style=\"font-weight: bold\">  [ </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-6.6769195</span><span style=\"font-weight: bold\">    </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.7138944</span><span style=\"font-weight: bold\">    </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.8476305</span><span style=\"font-weight: bold\">  </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37.5526</span><span style=\"font-weight: bold\">       </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2411785</span>\n",
       "<span style=\"font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-10.840807</span><span style=\"font-weight: bold\">  ]</span>\n",
       "<span style=\"font-weight: bold\">  [ </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34.355415</span><span style=\"font-weight: bold\">    </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-6.8087406</span><span style=\"font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27.63369</span><span style=\"font-weight: bold\">    </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-17.313995</span><span style=\"font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-16.589275</span>\n",
       "<span style=\"font-weight: bold\">    </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20.30392</span><span style=\"font-weight: bold\">   ]]]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mattn_logits\u001b[0m\n",
       "\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m0.58258057\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m-6.9096413\u001b[0m\u001b[1m   \u001b[0m\u001b[1;36m32.7293\u001b[0m\u001b[1m     \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m18.75351\u001b[0m\u001b[1m    \u001b[0m\u001b[1;36m-12.444878\u001b[0m\n",
       "\u001b[1m    \u001b[0m\u001b[1;36m29.457623\u001b[0m\u001b[1m  \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1m[\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m6.389431\u001b[0m\u001b[1m    \u001b[0m\u001b[1;36m24.134903\u001b[0m\u001b[1m     \u001b[0m\u001b[1;36m4.4726806\u001b[0m\u001b[1m  \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m53.15055\u001b[0m\u001b[1m     \u001b[0m\u001b[1;36m23.586643\u001b[0m\n",
       "\u001b[1m    \u001b[0m\u001b[1;36m27.149685\u001b[0m\u001b[1m  \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-29.103306\u001b[0m\u001b[1m    \u001b[0m\u001b[1;36m18.96471\u001b[0m\u001b[1m     \u001b[0m\u001b[1;36m69.86938\u001b[0m\u001b[1m    \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m48.208244\u001b[0m\u001b[1m   \u001b[0m\u001b[1;36m-49.304134\u001b[0m\n",
       "\u001b[1m    \u001b[0m\u001b[1;36m38.2608\u001b[0m\u001b[1m    \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1;33m...\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1m[\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m10.397432\u001b[0m\u001b[1m   \u001b[0m\u001b[1;36m-38.604023\u001b[0m\u001b[1m    \u001b[0m\u001b[1;36m25.956514\u001b[0m\u001b[1m   \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m-30.788982\u001b[0m\u001b[1m    \u001b[0m\u001b[1;36m20.908705\u001b[0m\n",
       "\u001b[1m    \u001b[0m\u001b[1;36m77.33066\u001b[0m\u001b[1m   \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1m[\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m-6.6769195\u001b[0m\u001b[1m    \u001b[0m\u001b[1;36m5.7138944\u001b[0m\u001b[1m    \u001b[0m\u001b[1;36m9.8476305\u001b[0m\u001b[1m  \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m37.5526\u001b[0m\u001b[1m       \u001b[0m\u001b[1;36m1.2411785\u001b[0m\n",
       "\u001b[1m   \u001b[0m\u001b[1;36m-10.840807\u001b[0m\u001b[1m  \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1m[\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m34.355415\u001b[0m\u001b[1m    \u001b[0m\u001b[1;36m-6.8087406\u001b[0m\u001b[1m   \u001b[0m\u001b[1;36m27.63369\u001b[0m\u001b[1m    \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m-17.313995\u001b[0m\u001b[1m   \u001b[0m\u001b[1;36m-16.589275\u001b[0m\n",
       "\u001b[1m    \u001b[0m\u001b[1;36m20.30392\u001b[0m\u001b[1m   \u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">attn_logits mean: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.15942378342151642</span><span style=\"font-weight: bold\">, std: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31.27756118774414</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mattn_logits mean: \u001b[0m\u001b[1;36m-0.15942378342151642\u001b[0m\u001b[1m, std: \u001b[0m\u001b[1;36m31.27756118774414\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attn_logits = jnp.matmul(q, k.transpose((0, 2, 1)))\n",
    "print_matrix(\"attn_logits\", attn_logits)\n",
    "\n",
    "print(f\"[bold]attn_logits mean: {jnp.mean(attn_logits)}, std: {jnp.std(attn_logits)}[/bold]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOOOF!! The standard deviation (and therefore the variance) of our values has sky-rocketed! Let's plot a historgram of the values of the resultant matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram of attn_logits, y axis is log scale\n",
    "plt.hist(attn_logits.flatten(), bins=100);\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's apply the softmax and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">attn_weights</span>\n",
       "<span style=\"font-weight: bold\">[[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.7114778e-32</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.1836081e-35</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.2226629e-18</span><span style=\"font-weight: bold\"> </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.4492078e-24</span>\n",
       "<span style=\"font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2560164e-37</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.9816179e-19</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">  [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1625383e-33</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.9178798e-26</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.7099006e-34</span><span style=\"font-weight: bold\"> </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.3632078e-13</span>\n",
       "<span style=\"font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.4202667e-26</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2063388e-24</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">  [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000000e+00</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.2237502e-32</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.4114768e-10</span><span style=\"font-weight: bold\"> </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.1183873e-19</span>\n",
       "<span style=\"font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000000e+00</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0136427e-23</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">  </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span>\n",
       "<span style=\"font-weight: bold\">  [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.8082027e-31</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000000e+00</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.3209723e-24</span><span style=\"font-weight: bold\"> </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000000e+00</span>\n",
       "<span style=\"font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.1331973e-26</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.8041377e-02</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">  [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000000e+00</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000000e+00</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000000e+00</span><span style=\"font-weight: bold\"> </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.3019265e-33</span>\n",
       "<span style=\"font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000000e+00</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000000e+00</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">  [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.8961004e-12</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.3124943e-29</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1919438e-14</span><span style=\"font-weight: bold\"> </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.5952226e-34</span>\n",
       "<span style=\"font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.4210611e-34</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.8158733e-18</span><span style=\"font-weight: bold\">]]]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mattn_weights\u001b[0m\n",
       "\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m5.7114778e-32\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m3.1836081e-35\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m5.2226629e-18\u001b[0m\u001b[1m \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m4.4492078e-24\u001b[0m\n",
       "\u001b[1m   \u001b[0m\u001b[1;36m1.2560164e-37\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m1.9816179e-19\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1.1625383e-33\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m5.9178798e-26\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m1.7099006e-34\u001b[0m\u001b[1m \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m2.3632078e-13\u001b[0m\n",
       "\u001b[1m   \u001b[0m\u001b[1;36m3.4202667e-26\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m1.2063388e-24\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.0000000e+00\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m4.2237502e-32\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m5.4114768e-10\u001b[0m\u001b[1m \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m2.1183873e-19\u001b[0m\n",
       "\u001b[1m   \u001b[0m\u001b[1;36m0.0000000e+00\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m1.0136427e-23\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1;33m...\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m5.8082027e-31\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.0000000e+00\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m3.3209723e-24\u001b[0m\u001b[1m \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.0000000e+00\u001b[0m\n",
       "\u001b[1m   \u001b[0m\u001b[1;36m2.1331973e-26\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m6.8041377e-02\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.0000000e+00\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.0000000e+00\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.0000000e+00\u001b[0m\u001b[1m \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m3.3019265e-33\u001b[0m\n",
       "\u001b[1m   \u001b[0m\u001b[1;36m0.0000000e+00\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.0000000e+00\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m9.8961004e-12\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m1.3124943e-29\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m1.1919438e-14\u001b[0m\u001b[1m \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m3.5952226e-34\u001b[0m\n",
       "\u001b[1m   \u001b[0m\u001b[1;36m7.4210611e-34\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m7.8158733e-18\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">attn_weights mean: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.009999999776482582</span><span style=\"font-weight: bold\">, std: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.09621075540781021</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mattn_weights mean: \u001b[0m\u001b[1;36m0.009999999776482582\u001b[0m\u001b[1m, std: \u001b[0m\u001b[1;36m0.09621075540781021\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attn_weights = jax.nn.softmax(attn_logits)\n",
    "\n",
    "print_matrix(\"attn_weights\", attn_weights)\n",
    "print(f\"[bold]attn_weights mean: {jnp.mean(attn_weights)}, std: {jnp.std(attn_weights)}[/bold]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(attn_weights.flatten(), bins=100);\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see two peaks, one at 0 and another at 1, which tells us that there are many places where the softmax is pushed to its extreme values. As we saw before that has an effect on the gradients, specifically leading to really small gradient values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's Going On and How Do We Fix That?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for some math! Check out this [post](https://ai.stackexchange.com/questions/21237/why-does-this-multiplication-of-q-and-k-have-a-variance-of-d-k-in-scaled) for some more info!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `Q` and `K` matrices have values that are sampled from a standard normal distribution. Let's call values of `Q` random variables `X` and values of `K` random variables `Y`, where `X` and `Y` are independent random variables. Since all values will be independent and identically distributed (iid) let's consider an arbitrary entry in both matrices $X_ii$ and $Y_jj$\n",
    "\n",
    "$$ X_ii \\sim \\mathcal{N}(0, 1)$$\n",
    "$$ Y_jj \\sim \\mathcal{N}(0, 1)$$\n",
    "\n",
    "we also know that\n",
    "\n",
    "$$\\mathbb{E}[X_ii] = \\mathbb{E}[Y_jj] = 1$$\n",
    "$$Var[X_ii] = Var[Y_jj] = 1$$\n",
    "\n",
    "We observed earlier that when we multiply our two matrices, the variance explodes. Therefore, it would be great if we could figure out an expression for the variance of our matrix product since that could give us insights into what's going on. How do we find an expression for the variance of an entry of our result matrix? \n",
    "\n",
    "Let's start by calling our result matrix `R`, it's defined as \n",
    "\n",
    "$$R = Q \\cdot K^T$$\n",
    "\n",
    "What does a single entry in `R` look like? What are the operations that result in that value? \n",
    "Assuming you are familar with linear algebra, a single value of `R`, say $R_{r,c}$ is defined as the vector dot product between row `r` of the `Q` matrix and column `c` of the $K^T$ matrix. It looks something like this\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "- & Q_r & - \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "|\\\\\n",
    "K^T_c \\\\\n",
    "|\\\\\n",
    "\\end{bmatrix} = Q_{r1} * K^T_{c1} + Q_{r2} * K^T_{c2} + \\ldots = \\sum_{d=dim(Q_{r})=dim(K^T_{c})}Q_{rd} * K^T_{cd}\n",
    "$$\n",
    "\n",
    "Let's take a quick step back and remember that values from our `Q` and `K` matrices are random variables `X` and `Y`. This means that a single entry of our `R` (result) matrix will be a random variable as well. Let's call it `Z_l`. The expected value and variance of `Z_l` will be given by\n",
    "\n",
    "$$\\mathbb{E}[Z_l] = \\mathbb{E}[\\sum_{d}Q_{rd} * K^T_{cd}] = \\mathbb{E}[\\sum_{d}X_{rd} * Y_{cd}]$$\n",
    "$$Var[Z_l] = Var[\\sum_{d}Q_{rd} * K^T_{cd}] = Var[\\sum_{d}X_{rd} * Y_{cd}]$$\n",
    "\n",
    "Cool. So what on earth do we do with that? We recall that `X` and `Y` are independent and identically distributed. We also recall the following proporties for expectations and variances of IID variables.\n",
    "\n",
    "$$\\mathbb{E}[X + Y] = \\mathbb{E}[X] + \\mathbb{E}[Y]$$\n",
    "$$Var[X + Y] = Var[X] + Var[Y]$$\n",
    "\n",
    "This means we can rewrite our equations from before as\n",
    "\n",
    "$$\\mathbb{E}[Z_l] = \\mathbb{E}[\\sum_{d}X_{rd} * Y_{cd}] = \\sum_{d}\\mathbb{E}[X_{rd} * Y_{cd}]$$\n",
    "$$Var[Z_l] = Var[\\sum_{d}Q_{rd} * K^T_{cd}] = \\sum_{d}Var[X_{rd} * Y_{cd}]$$\n",
    "\n",
    "Ok, awesome! But what now?\n",
    "Let's tackle our expected value first. We recall another property of expectations of IID random variables\n",
    "$$\\mathbb{E}[XY] = \\mathbb{E}[X]\\mathbb{E}[Y]$$\n",
    "\n",
    "Which lets us re-write our expected value of `Z` as \n",
    "$$\\mathbb{E}[Z_l] = \\sum_{d}\\mathbb{E}[X_{rd} * Y_{cd}] = \\sum_{d}\\mathbb{E}[X_{rd}] * \\mathbb{E}[Y_{cd}] = \\sum_{d}0 * 0 = 0$$\n",
    "\n",
    "That's great, because it's in line with what we saw when we did our experiment earlier. However, what do we do with the variance? That one is a bit tougher. I did not recall the equation for the variance of the product of two random variables, so I re-derived it from the defintion of variance. The derivation will be added at the very end, since it takes up a bit of space. I would have personally wanted to see it so I'm sure others will too! \n",
    "\n",
    "$$Var[XY] = (Var[X] + \\mathbb{E}[X]^2) * (Var[Y] + \\mathbb{E}[Y]^2)$$\n",
    "\n",
    "In our case, this means that \n",
    "\n",
    "$$Var[X_{rd} * Y_{cd}] = (Var[X_{rd}] + \\mathbb{E}[X_{rd}]^2) * (Var[Y_{cd}] + \\mathbb{E}[Y_{cd}]^2) = Var[X_{rd}] * Var[Y_{cd}]$$\n",
    "\n",
    "Finally, we substitute this result into our earlier definition of $Var[Z_l]$ to get\n",
    "\n",
    "$$Var[Z_l] = \\sum_{d}Var[X_{rd} * Y_{cd}] = \\sum_{d}Var[X_{rd}] * Var[Y_{cd}]$$\n",
    "\n",
    "From earlier we know that $Var[X_{rd}] = Var[Y_{cd}] = 1$, so therefore\n",
    "\n",
    "$$Var[Z_l] = \\sum_{d}Var[X_{rd}] * Var[Y_{cd}] = \\sum_{d} 1 = d$$\n",
    "\n",
    "Putting all of that together, we get that our $Z_{ll}$ variable, which is a single entry of our result `R` matrix (product between `Q` and `K` matrices) is a random variable distributed according to \n",
    "\n",
    "$$Z_{ll} \\sim \\mathcal{N}(0, \\sqrt{d})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this means is, that when we multiply the queries and keys matrices, we get values that have a much larger range than the one we started out with. Our initial `Q` and `K` matrices had a variance of `1` while our result matrix has a variance of $d^2$. Does this line up with our experimental observations? \n",
    "\n",
    "Well, from before we saw that our logits matrix had mean and std of \n",
    "\n",
    "`attn_logits mean: -0.15942378342151642, std: 31.27756118774414`\n",
    "\n",
    "Squaring the standard deviation we get `961`, while our `d` in this case is `1000`, so yes, our experimental observations are pretty close!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might already see how we are going to fix it. We want the variance of our result matrix to be equal to `1`, in other words $Var[Z_{ll}] = 1$\n",
    "\n",
    "What do we need to do for that? Let's see!\n",
    "\n",
    "$$Var[Z_{ll}] = \\sum_{d}Var[X_{rd}] * Var[Y_{cd}] = \\sum_{d} 1 = d$$\n",
    "\n",
    "Therefore \n",
    "\n",
    "$$\\frac{1}{d} * Var[Z_{ll}] = \\frac{1}{d} * \\sum_{d}Var[X_{rd}] * Var[Y_{cd}] = \\frac{1}{d} * \\sum_{d} 1 = \\frac{d}{d} = 1$$\n",
    "\n",
    "However, we know that \n",
    "$$Var[cX] = \\mathbb{E}[c^2X^2] - \\mathbb{E}[cX]^2 = c^2 * \\mathbb{E}[X^2] - c^2 * \\mathbb{E}[X]^2 = c^2 * (\\mathbb{E}[X^2] - \\mathbb{E}[X]^2) = c^2 * Var[X]$$\n",
    "\n",
    "Aaaand, therefore\n",
    "\n",
    "$$\\frac{1}{d} * Var[Z_l] = Var[\\frac{1}{\\sqrt{d}} Z_{ll}]$$\n",
    "\n",
    "Finally, we see that by dividing the product of the `Q` and `K` matrices by the square root of `d`, we ensure that the entries in our result matrix have a variance of 1! \n",
    "\n",
    "Let's see this in code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">attn_logits</span>\n",
       "<span style=\"font-weight: bold\">[[[ </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01842282</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.21850204</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0349914</span><span style=\"font-weight: bold\">  </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5930381</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3935416</span>\n",
       "<span style=\"font-weight: bold\">    </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.93153185</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">  [ </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.20205155</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7632127</span><span style=\"font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.14143857</span><span style=\"font-weight: bold\"> </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.680768</span><span style=\"font-weight: bold\">    </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7458752</span>\n",
       "<span style=\"font-weight: bold\">    </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.85854846</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">  [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.92032737</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5997168</span><span style=\"font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.2094638</span><span style=\"font-weight: bold\">  </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.5244786</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.5591336</span>\n",
       "<span style=\"font-weight: bold\">    </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2099128</span><span style=\"font-weight: bold\"> ]</span>\n",
       "<span style=\"font-weight: bold\">  </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span>\n",
       "<span style=\"font-weight: bold\">  [ </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.32879567</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.2207664</span><span style=\"font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.82081705</span><span style=\"font-weight: bold\"> </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.9736331</span><span style=\"font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6611913</span>\n",
       "<span style=\"font-weight: bold\">    </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.4454103</span><span style=\"font-weight: bold\"> ]</span>\n",
       "<span style=\"font-weight: bold\">  [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.21114273</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.18068922</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3114094</span><span style=\"font-weight: bold\">  </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1875175</span><span style=\"font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.03924951</span>\n",
       "<span style=\"font-weight: bold\">   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.3428164</span><span style=\"font-weight: bold\"> ]</span>\n",
       "<span style=\"font-weight: bold\">  [ </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0864136</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.21531129</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.87385404</span><span style=\"font-weight: bold\"> </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.54751664</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.52459896</span>\n",
       "<span style=\"font-weight: bold\">    </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.64206636</span><span style=\"font-weight: bold\">]]]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mattn_logits\u001b[0m\n",
       "\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.01842282\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m-0.21850204\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m1.0349914\u001b[0m\u001b[1m  \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m0.5930381\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m-0.3935416\u001b[0m\n",
       "\u001b[1m    \u001b[0m\u001b[1;36m0.93153185\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1m[\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.20205155\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m0.7632127\u001b[0m\u001b[1m   \u001b[0m\u001b[1;36m0.14143857\u001b[0m\u001b[1m \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m1.680768\u001b[0m\u001b[1m    \u001b[0m\u001b[1;36m0.7458752\u001b[0m\n",
       "\u001b[1m    \u001b[0m\u001b[1;36m0.85854846\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.92032737\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m0.5997168\u001b[0m\u001b[1m   \u001b[0m\u001b[1;36m2.2094638\u001b[0m\u001b[1m  \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m1.5244786\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m-1.5591336\u001b[0m\n",
       "\u001b[1m    \u001b[0m\u001b[1;36m1.2099128\u001b[0m\u001b[1m \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1;33m...\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1m[\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.32879567\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m-1.2207664\u001b[0m\u001b[1m   \u001b[0m\u001b[1;36m0.82081705\u001b[0m\u001b[1m \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m-0.9736331\u001b[0m\u001b[1m   \u001b[0m\u001b[1;36m0.6611913\u001b[0m\n",
       "\u001b[1m    \u001b[0m\u001b[1;36m2.4454103\u001b[0m\u001b[1m \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.21114273\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m0.18068922\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m0.3114094\u001b[0m\u001b[1m  \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m1.1875175\u001b[0m\u001b[1m   \u001b[0m\u001b[1;36m0.03924951\u001b[0m\n",
       "\u001b[1m   \u001b[0m\u001b[1;36m-0.3428164\u001b[0m\u001b[1m \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1m[\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m1.0864136\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m-0.21531129\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m0.87385404\u001b[0m\u001b[1m \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m-0.54751664\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m-0.52459896\u001b[0m\n",
       "\u001b[1m    \u001b[0m\u001b[1;36m0.64206636\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">attn_logits mean: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.005041422322392464</span><span style=\"font-weight: bold\">, std: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9890833497047424</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mattn_logits mean: \u001b[0m\u001b[1;36m-0.005041422322392464\u001b[0m\u001b[1m, std: \u001b[0m\u001b[1;36m0.9890833497047424\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using the same q and k matrices\n",
    "\n",
    "attn_logits = jnp.matmul(q, k.transpose((0, 2, 1)))\n",
    "scaled_attn_logits = attn_logits / jnp.sqrt(d_k)\n",
    "\n",
    "print_matrix(\"attn_logits\", scaled_attn_logits)\n",
    "\n",
    "print(f\"[bold]attn_logits mean: {jnp.mean(scaled_attn_logits)}, std: {jnp.std(scaled_attn_logits)}[/bold]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YESSS!! The mean is (close to) 0 and the variance (and std) are close to 1! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram of attn_logits, y axis is log scale\n",
    "plt.hist(scaled_attn_logits.flatten(), bins=100);\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">attn_weights</span>\n",
       "<span style=\"font-weight: bold\">[[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00673581</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0053149</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01861573</span><span style=\"font-weight: bold\"> </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01196581</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00446145</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01678604</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">  [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00707698</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01240387</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00666076</span><span style=\"font-weight: bold\"> </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0310489</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01219067</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0136446</span><span style=\"font-weight: bold\"> ]</span>\n",
       "<span style=\"font-weight: bold\">  [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00214672</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00981574</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.04909388</span><span style=\"font-weight: bold\"> </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.02474811</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0011333</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01806874</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">  </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span>\n",
       "<span style=\"font-weight: bold\">  [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00887805</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00188517</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01452111</span><span style=\"font-weight: bold\"> </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00241368</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01237871</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0737143</span><span style=\"font-weight: bold\"> ]</span>\n",
       "<span style=\"font-weight: bold\">  [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00365361</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0054062</span><span style=\"font-weight: bold\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00616117</span><span style=\"font-weight: bold\"> </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01479628</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00469317</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00320285</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">  [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01864362</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00507222</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01507359</span><span style=\"font-weight: bold\"> </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">...</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00363851</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00372286</span><span style=\"font-weight: bold\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01195509</span><span style=\"font-weight: bold\">]]]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mattn_weights\u001b[0m\n",
       "\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.00673581\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.0053149\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m0.01861573\u001b[0m\u001b[1m \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.01196581\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.00446145\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.01678604\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.00707698\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.01240387\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.00666076\u001b[0m\u001b[1m \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.0310489\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m0.01219067\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.0136446\u001b[0m\u001b[1m \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.00214672\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.00981574\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.04909388\u001b[0m\u001b[1m \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.02474811\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.0011333\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m0.01806874\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1;33m...\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.00887805\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.00188517\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.01452111\u001b[0m\u001b[1m \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.00241368\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.01237871\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.0737143\u001b[0m\u001b[1m \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.00365361\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.0054062\u001b[0m\u001b[1m  \u001b[0m\u001b[1;36m0.00616117\u001b[0m\u001b[1m \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.01479628\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.00469317\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.00320285\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m  \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.01864362\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.00507222\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.01507359\u001b[0m\u001b[1m \u001b[0m\u001b[1;33m...\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.00363851\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.00372286\u001b[0m\u001b[1m \u001b[0m\u001b[1;36m0.01195509\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">attn_weights mean: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.009999998845160007</span><span style=\"font-weight: bold\">, std: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.011963767930865288</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mattn_weights mean: \u001b[0m\u001b[1;36m0.009999998845160007\u001b[0m\u001b[1m, std: \u001b[0m\u001b[1;36m0.011963767930865288\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attn_weights = jax.nn.softmax(scaled_attn_logits)\n",
    "\n",
    "print_matrix(\"attn_weights\", attn_weights)\n",
    "print(f\"[bold]attn_weights mean: {jnp.mean(attn_weights)}, std: {jnp.std(attn_weights)}[/bold]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(attn_weights.flatten(), bins=100);\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving Variance Of A Product of `X` and `Y`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align*}\n",
    "X &\\sim \\mathcal{N}(0,1) \\\\\n",
    "Y &\\sim \\mathcal{N}(0,1) \\\\\n",
    "X \\text{ and } Y &\\text{ are IID} \\\\\n",
    "\\text{Var}[XY] &= \\mathbb{E}[X^2Y^2] - \\mathbb{E}[XY]^2 \\\\\n",
    "&= \\mathbb{E}[X^2]\\mathbb{E}[Y^2] - \\mathbb{E}[X]^2\\mathbb{E}[Y^2] \\\\\n",
    "&= \\mathbb{E}[X^2]\\mathbb{E}[Y^2] - \\mathbb{E}[Y^2]\\mathbb{E}[X^2] + \\mathbb{E}[Y^2]\\mathbb{E}[X^2] \\\\\n",
    "&= \\mathbb{E}[X^2] \\cdot \\mathbb{E}[Y^2] - \\mathbb{E}[Y^2] \\cdot \\mathbb{E}[X] ^ 2 + \\mathbb{E}[Y^2] \\cdot \\mathbb{E}[X]^2 \\\\\n",
    "&= \\mathbb{E}[Y^2] \\left( Var[X] + \\mathbb{E}[X]^2 \\right) = \\mathbb{E}[Y^2] * B\\\\\n",
    "&= \\mathbb{E}[Y^2] * B = \\mathbb{E}[Y^2] * B - \\mathbb{E}[Y]^2 * B + \\mathbb{E}[Y]^2 * B\\\\\n",
    "&= B * \\left( Var[Y] + \\mathbb{E}[Y]^2 \\right)\\\\\n",
    "&= \\left( Var[X] + \\mathbb{E}[X]^2 \\right) * \\left( Var[Y] + \\mathbb{E}[Y]^2 \\right)\\\\\n",
    "&= \\left( Var[X] + 0 \\right) * \\left( Var[Y] + 0 \\right)\\\\\n",
    "&= Var[X]*Var[Y]\\\\\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
